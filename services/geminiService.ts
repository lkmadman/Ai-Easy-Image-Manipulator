import { GoogleGenAI } from "@google/genai";
import { cleanBase64 } from "../utils/imageUtils";

// Initialize Gemini API
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Sends an image and a prompt to Gemini for editing.
 * Accepts an optional mask image to guide the edit.
 */
export const editImageWithGemini = async (
  imageBase64: string,
  prompt: string,
  maskImageBase64?: string
): Promise<string> => {
  try {
    const cleanData = cleanBase64(imageBase64);
    const parts: any[] = [
        {
          inlineData: {
            mimeType: 'image/png',
            data: cleanData,
          },
        }
    ];

    let fullPrompt = `Task: Edit the provided image based on this instruction: "${prompt}".`;

    if (maskImageBase64) {
      const cleanMask = cleanBase64(maskImageBase64);
      parts.push({
        inlineData: {
          mimeType: 'image/png',
          data: cleanMask,
        },
      });
      fullPrompt += " The second image provided is a mask. Only edit the pixels in the first image that correspond to the white areas in the mask. Leave the rest of the image exactly as is.";
    } else {
       fullPrompt += " Edit the image globally or find the object described.";
    }
    
    fullPrompt += " Ensure the edit is seamless, photorealistic, and high quality. Maintain the original image style and resolution.";

    parts.push({ text: fullPrompt });

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: parts,
      },
    });

    if (response.candidates && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }

    throw new Error("No image generated by the model.");

  } catch (error: any) {
    console.error("Gemini API Error:", error);
    throw new Error(error.message || "Failed to process image.");
  }
};

/**
 * Generates a black and white segmentation mask for a specific object.
 */
export const generateSegmentationMask = async (
  imageBase64: string,
  objectDescription: string
): Promise<string> => {
  try {
    const cleanData = cleanBase64(imageBase64);
    const prompt = `Generate a precise black and white segmentation mask for the ${objectDescription || 'main object'}. The object should be pure white (#FFFFFF) and the background pure black (#000000). Ensure clean edges.`;

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [
          { inlineData: { mimeType: 'image/png', data: cleanData } },
          { text: prompt }
        ],
      },
    });

    if (response.candidates && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    throw new Error("No mask generated by the model.");
  } catch (error: any) {
    console.error("Mask Generation Error:", error);
    throw new Error(error.message || "Failed to generate mask.");
  }
};

/**
 * Identifies the main object in a cropped image to provide prompt suggestions.
 */
export const identifyObject = async (cropBase64: string): Promise<string> => {
  try {
    const cleanData = cleanBase64(cropBase64);
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: {
        parts: [
          { inlineData: { mimeType: 'image/png', data: cleanData } },
          { text: "Identify the main single object or feature visible in this image crop. Return ONLY the name (e.g. 'hair', 'hand', 'car', 'sky', 'shirt'). One or two words max." }
        ]
      }
    });

    return response.text?.trim() || "";
  } catch (error) {
    console.warn("Identification failed", error);
    return "";
  }
};